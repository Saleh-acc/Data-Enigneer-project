[2025-02-08T19:01:06.650+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-08T19:01:06.664+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: account_dim_gen.generate_account_dim_data scheduled__2025-01-14T00:00:00+00:00 [queued]>
[2025-02-08T19:01:06.671+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: account_dim_gen.generate_account_dim_data scheduled__2025-01-14T00:00:00+00:00 [queued]>
[2025-02-08T19:01:06.672+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-02-08T19:01:06.683+0000] {taskinstance.py:2888} INFO - Executing <Task(PythonOperator): generate_account_dim_data> on 2025-01-14 00:00:00+00:00
[2025-02-08T19:01:06.691+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1003) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-02-08T19:01:06.693+0000] {standard_task_runner.py:72} INFO - Started process 1015 to run task
[2025-02-08T19:01:06.691+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'account_dim_gen', 'generate_account_dim_data', 'scheduled__2025-01-14T00:00:00+00:00', '--job-id', '130', '--raw', '--subdir', 'DAGS_FOLDER/account_dim_gen.py', '--cfg-path', '/tmp/tmpzcvaexqs']
[2025-02-08T19:01:06.694+0000] {standard_task_runner.py:105} INFO - Job 130: Subtask generate_account_dim_data
[2025-02-08T19:01:06.731+0000] {task_command.py:467} INFO - Running <TaskInstance: account_dim_gen.generate_account_dim_data scheduled__2025-01-14T00:00:00+00:00 [running]> on host 2c1cd59afcc0
[2025-02-08T19:01:06.802+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Saleh' AIRFLOW_CTX_DAG_ID='account_dim_gen' AIRFLOW_CTX_TASK_ID='generate_account_dim_data' AIRFLOW_CTX_EXECUTION_DATE='2025-01-14T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-01-14T00:00:00+00:00'
[2025-02-08T19:01:06.803+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-02-08T19:01:06.817+0000] {logging_mixin.py:190} INFO - CSV file ./account_dim_large_data.csv with 50 row has been generated successfully!
[2025-02-08T19:01:06.818+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-02-08T19:01:06.824+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-02-08T19:01:06.825+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=account_dim_gen, task_id=generate_account_dim_data, run_id=scheduled__2025-01-14T00:00:00+00:00, execution_date=20250114T000000, start_date=20250208T190106, end_date=20250208T190106
[2025-02-08T19:01:06.867+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-02-08T19:01:06.880+0000] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-08T19:01:06.882+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-02-08T20:41:21.100+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-08T20:41:21.122+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: account_dim_gen.generate_account_dim_data scheduled__2025-01-14T00:00:00+00:00 [queued]>
[2025-02-08T20:41:21.131+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: account_dim_gen.generate_account_dim_data scheduled__2025-01-14T00:00:00+00:00 [queued]>
[2025-02-08T20:41:21.132+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-02-08T20:41:21.145+0000] {taskinstance.py:2888} INFO - Executing <Task(PythonOperator): generate_account_dim_data> on 2025-01-14 00:00:00+00:00
[2025-02-08T20:41:21.156+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2092) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-02-08T20:41:21.157+0000] {standard_task_runner.py:72} INFO - Started process 2104 to run task
[2025-02-08T20:41:21.156+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'account_dim_gen', 'generate_account_dim_data', 'scheduled__2025-01-14T00:00:00+00:00', '--job-id', '356', '--raw', '--subdir', 'DAGS_FOLDER/account_dim_gen.py', '--cfg-path', '/tmp/tmp7hgt27kg']
[2025-02-08T20:41:21.159+0000] {standard_task_runner.py:105} INFO - Job 356: Subtask generate_account_dim_data
[2025-02-08T20:41:21.199+0000] {task_command.py:467} INFO - Running <TaskInstance: account_dim_gen.generate_account_dim_data scheduled__2025-01-14T00:00:00+00:00 [running]> on host 7e959c1a2a8b
[2025-02-08T20:41:21.277+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Saleh' AIRFLOW_CTX_DAG_ID='account_dim_gen' AIRFLOW_CTX_TASK_ID='generate_account_dim_data' AIRFLOW_CTX_EXECUTION_DATE='2025-01-14T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-01-14T00:00:00+00:00'
[2025-02-08T20:41:21.278+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-02-08T20:41:21.296+0000] {logging_mixin.py:190} INFO - CSV file ./account_dim_large_data.csv with 50 row has been generated successfully!
[2025-02-08T20:41:21.296+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-02-08T20:41:21.304+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-02-08T20:41:21.305+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=account_dim_gen, task_id=generate_account_dim_data, run_id=scheduled__2025-01-14T00:00:00+00:00, execution_date=20250114T000000, start_date=20250208T204121, end_date=20250208T204121
[2025-02-08T20:41:21.332+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-02-08T20:41:21.349+0000] {local_task_job_runner.py:127} ERROR - Received SIGTERM. Terminating subprocesses
[2025-02-08T20:41:21.349+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 143
[2025-02-08T20:41:21.356+0000] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-08T20:41:21.359+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/cursor.py", line 991, in fetchall
    rows = dbapi_cursor.fetchall()
           ^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.InterfaceError: cursor already closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3878, in _schedule_downstream_tasks
    info = dag_run.task_instance_scheduling_decisions(session)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagrun.py", line 967, in task_instance_scheduling_decisions
    tis = self.get_task_instances(session=session, state=State.task_states)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagrun.py", line 629, in get_task_instances
    return DagRun.fetch_task_instances(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagrun.py", line 566, in fetch_task_instances
    return session.scalars(tis).all()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/result.py", line 1476, in all
    return self._allrows()
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/result.py", line 401, in _allrows
    rows = self._fetchall_impl()
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/result.py", line 1389, in _fetchall_impl
    return self._real_result._fetchall_impl()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/result.py", line 1813, in _fetchall_impl
    return list(self.iterator)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/loading.py", line 147, in chunks
    fetch = cursor._raw_all_rows()
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/result.py", line 392, in _raw_all_rows
    rows = self._fetchall_impl()
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/cursor.py", line 1819, in _fetchall_impl
    return self.cursor_strategy.fetchall(self, self.cursor)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/cursor.py", line 995, in fetchall
    self.handle_exception(result, dbapi_cursor, e)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/cursor.py", line 955, in handle_exception
    result.connection._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/cursor.py", line 991, in fetchall
    rows = dbapi_cursor.fetchall()
           ^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.InterfaceError: (psycopg2.InterfaceError) cursor already closed
(Background on this error at: https://sqlalche.me/e/14/rvf5)
[2025-02-08T20:41:21.363+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
